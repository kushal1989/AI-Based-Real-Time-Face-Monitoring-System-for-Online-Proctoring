{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2251605e-95ce-49ab-aae8-adb95647c49a",
   "metadata": {},
   "source": [
    "# AI-Based Real-Time Face Monitoring System for Online Proctoring \n",
    "## (Prevent Proxy / Impersonation in Online Exams & Interviews)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Problem\n",
    "\n",
    "Online exams, interviews, and certification tests have become widespread across:\n",
    "\n",
    "- Universities and colleges  \n",
    "- Recruitment platforms  \n",
    "- Online certification providers  \n",
    "- Corporate assessments  \n",
    "\n",
    "However, remote assessments face serious integrity challenges, such as:\n",
    "\n",
    "- Candidates leaving their seats during exams  \n",
    "- Proxy candidates replacing the original person  \n",
    "- Multiple people appearing on camera  \n",
    "- Lack of continuous human monitoring  \n",
    "\n",
    "These issues lead to:\n",
    "\n",
    "- Compromised exam credibility  \n",
    "- Unfair evaluation  \n",
    "- Loss of trust in online assessment systems  \n",
    "\n",
    "From an organizational and business perspective, impersonation results in:\n",
    "\n",
    "- Invalid assessment outcomes  \n",
    "- Increased manual proctoring costs  \n",
    "- Legal and compliance risks  \n",
    "- Brand reputation damage  \n",
    "- Reduced acceptance of online examinations  \n",
    "\n",
    "Manual monitoring using human proctors is:\n",
    "\n",
    "- Expensive  \n",
    "- Error-prone  \n",
    "- Not scalable for large-scale exams  \n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Business Objective\n",
    "\n",
    "The primary objective of the **AI-Based Real-Time Face Monitoring System for Online Proctoring** is to:\n",
    "\n",
    "- Continuously monitor the candidate through webcam video  \n",
    "- Detect face absence during an active session  \n",
    "- Detect multiple faces indicating possible impersonation  \n",
    "- Generate real-time alerts and logs for suspicious activity  \n",
    "- Improve fairness and integrity in online examinations  \n",
    "\n",
    "Secondary objectives include:\n",
    "\n",
    "- Reducing dependency on manual invigilators  \n",
    "- Providing automated evidence for exam violations  \n",
    "- Enabling scalable remote assessment monitoring  \n",
    "- Supporting cost-effective proctoring solutions  \n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Business Constraints\n",
    "\n",
    "| Constraint Type | Description |\n",
    "|----------------|-------------|\n",
    "| Cost Constraint | The system should work using a standard webcam without requiring expensive sensors or hardware. |\n",
    "| Latency Constraint | Face detection and alerts must occur in real time to prevent misuse during the exam. |\n",
    "| Environmental Constraint | Performance may vary with lighting conditions, camera quality, and background environment. |\n",
    "| Privacy Constraint | Captured video and images must comply with data privacy, consent, and institutional policies. |\n",
    "| Accuracy Constraint | False warnings should be minimized to avoid unnecessary interruptions. |\n",
    "| Hardware Constraint | The system should run efficiently on low-end devices such as laptops and basic PCs. |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Future Goals & Roadmap\n",
    "\n",
    "### 5.1 Face Recognition Enhancement\n",
    "- Integrate facial recognition for candidate identity verification  \n",
    "- Detect impersonation even when only one face is present  \n",
    "\n",
    "### 5.2 Behavioral Monitoring\n",
    "- Head movement analysis  \n",
    "- Eye gaze and attention tracking  \n",
    "- Long-term face absence detection  \n",
    "\n",
    "### 5.3 Multi-Source Monitoring\n",
    "- Screen activity monitoring  \n",
    "- Multiple camera support for high-security exams  \n",
    "\n",
    "### 5.4 Cloud-Based Exam Analytics\n",
    "- Centralized dashboards for:\n",
    "  - Violation statistics  \n",
    "  - Candidate risk analysis  \n",
    "  - Exam integrity reports  \n",
    "\n",
    "### 5.5 Integration with Examination Platforms\n",
    "- Learning Management Systems (LMS)  \n",
    "- Online exam portals  \n",
    "- Automated compliance and audit reports  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Future Market Opportunity\n",
    "\n",
    "The rapid growth of online education and remote hiring has increased demand for:\n",
    "\n",
    "- Automated online proctoring solutions  \n",
    "- AI-assisted exam monitoring systems  \n",
    "- Secure digital assessment platforms  \n",
    "\n",
    "High adoption potential exists in:\n",
    "\n",
    "- Universities and educational institutions  \n",
    "- Corporate recruitment and assessments  \n",
    "- Government and competitive examinations  \n",
    "- Certification bodies  \n",
    "\n",
    "Emerging markets such as **India, Southeast Asia, and the Middle East** show strong growth in online assessment adoption.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary (Executive View)\n",
    "\n",
    "The **AI-Based Real-Time Face Monitoring System for Online Proctoring** is a practical and cost-effective solution that:\n",
    "\n",
    "- Enhances integrity of online exams  \n",
    "- Prevents proxy and impersonation attempts  \n",
    "- Reduces operational and monitoring costs  \n",
    "- Improves trust in remote assessments  \n",
    "- Supports scalable digital examination systems  \n",
    "\n",
    "This system serves as a foundational component for:\n",
    "\n",
    "- Intelligent online proctoring platforms  \n",
    "- Secure remote assessments  \n",
    "- AI-enabled education technologies  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba492f3e-e605-4c9e-93d4-1370f001e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# -------------------- SETUP --------------------\n",
    "\n",
    "os.makedirs(\"screenshots\", exist_ok=True)\n",
    "\n",
    "csv_exists = os.path.exists(\"violation_log.csv\")\n",
    "csv_file = open(\"violation_log.csv\", \"a\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "if not csv_exists:\n",
    "    csv_writer.writerow([\"Time\", \"Event\", \"Image\"])\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(\n",
    "    min_detection_confidence=0.7,\n",
    "    model_selection=0\n",
    ")\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# -------------------- STATE VARIABLES --------------------\n",
    "\n",
    "baseline_x = None\n",
    "MOVE_THRESHOLD = 0.04\n",
    "\n",
    "previous_direction = \"CENTER\"\n",
    "direction_start_time = None\n",
    "DIRECTION_HOLD_TIME = 1.0\n",
    "\n",
    "last_event_time = 0\n",
    "COOLDOWN = 2\n",
    "\n",
    "left_count = 0\n",
    "right_count = 0\n",
    "\n",
    "# -------------------- MAIN LOOP --------------------\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(rgb)\n",
    "\n",
    "    face_count = len(results.detections) if results.detections else 0\n",
    "    direction = \"CENTER\"\n",
    "    status = \"OK\"\n",
    "    violation = False\n",
    "\n",
    "    # -------- FACE STATUS --------\n",
    "    if face_count == 0:\n",
    "        status = \"FACE MISSING\"\n",
    "        violation = True\n",
    "        baseline_x = None\n",
    "    elif face_count > 1:\n",
    "        status = \"MULTIPLE FACES\"\n",
    "        violation = True\n",
    "\n",
    "    # -------- LEFT / RIGHT DETECTION --------\n",
    "    if results.detections and face_count == 1:\n",
    "        det = results.detections[0]\n",
    "        drawing.draw_detection(frame, det)\n",
    "\n",
    "        bbox = det.location_data.relative_bounding_box\n",
    "        center_x = bbox.xmin + bbox.width / 2\n",
    "\n",
    "        if baseline_x is None:\n",
    "            baseline_x = center_x\n",
    "\n",
    "        diff = center_x - baseline_x\n",
    "        if diff < -MOVE_THRESHOLD:\n",
    "            direction = \"LEFT\"\n",
    "        elif diff > MOVE_THRESHOLD:\n",
    "            direction = \"RIGHT\"\n",
    "\n",
    "    now = time.time()\n",
    "\n",
    "    # -------- DIRECTION HOLD LOGIC --------\n",
    "    if direction != previous_direction:\n",
    "        direction_start_time = now\n",
    "        previous_direction = direction\n",
    "\n",
    "    elif direction in [\"LEFT\", \"RIGHT\"] and direction_start_time:\n",
    "        if now - direction_start_time >= DIRECTION_HOLD_TIME:\n",
    "            if direction == \"LEFT\":\n",
    "                left_count += 1\n",
    "            else:\n",
    "                right_count += 1\n",
    "            violation = True\n",
    "            direction_start_time = None\n",
    "\n",
    "    # -------- LOGGING --------\n",
    "    if violation and (now - last_event_time) > COOLDOWN:\n",
    "        winsound.Beep(2000, 300)\n",
    "\n",
    "        ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        event = status if status != \"OK\" else direction.lower()\n",
    "        img_path = f\"screenshots/{event}_{ts}.jpg\"\n",
    "\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        csv_writer.writerow([ts, event, img_path])\n",
    "\n",
    "        last_event_time = now\n",
    "\n",
    "    # -------------------- UI (PROFESSIONAL HUD) --------------------\n",
    "\n",
    "    # Overlay panel\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (330, 140), (30, 30, 30), -1)\n",
    "    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "    cv2.rectangle(frame, (10, 10), (330, 140), (200, 200, 200), 1)\n",
    "\n",
    "    # Text info\n",
    "    cv2.putText(frame, f\"Faces : {face_count}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"Left  : {left_count}\", (20, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"Right : {right_count}\", (20, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    # -------- TRAFFIC LIGHT (FIXED) --------\n",
    "    light_color = (0,255,0) if not violation else (0,0,255)\n",
    "    cv2.circle(frame, (300, 45), 10, light_color, -1)\n",
    "\n",
    "    # Status text\n",
    "    cv2.putText(frame, f\"STATUS: {status}\", (20, 130),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, light_color, 2)\n",
    "\n",
    "    cv2.imshow(\"AI-Based Face Monitoring System\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# -------------------- CLEANUP --------------------\n",
    "\n",
    "video.release()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b90378-6767-45d9-bedc-1576f6bf74d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
